<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Savvas Papaioannou </title> <meta name="author" content="Savvas Papaioannou"> <meta name="description" content="Research Scientist at KIOS CoE, University of Cyprus "> <meta name="keywords" content="Autonomous-systems, Inelligent-agents, UAVs, Control, Optimization, AI"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://savvas-papaioannou.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Savvas</span> Papaioannou </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/awards">awards </a> </li> <li class="nav-item "> <a class="nav-link" href="/media">media </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">misc </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/service">service</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/teaching">teaching</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/contact">contact</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <p>More details about my publications as well as pre-prints of recent papers can be found in my <a href="https://www.researchgate.net/profile/Savvas-Papaioannou" rel="external nofollow noopener" target="_blank">Research Gate</a> page, <a href="https://scholar.google.com/citations?user=liBM_1kAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Google Scholar</a>, and <a href="https://dblp.org/pid/129/5573" rel="external nofollow noopener" target="_blank">DBLP</a>.</p> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/RAM2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="RAM2025.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="RAM2025" class="col-sm-8"> <div class="title">Cooperative Aerial Robot Inspection Challenge: A Benchmark for Heterogeneous Multi-UAV Planning and Lessons Learned</div> <div class="author"> Muqing Cao, Thien-Minh Nguyen, Shenghai Yuan, Andreas Anastasiou, Angelos Zacharia, <em>Savvas Papaioannou</em>, and <span class="more-authors" title="click to view 9 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '9 more authors' ? 'Panayiotis Kolios, Christos G. Panayiotou, Marios M. Polycarpou, Xinhang Xu, Mingjie Zhang, Fei Gao, Boyu Zhou, Ben M. Chen, Lihua Xie' : '9 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">9 more authors</span> </div> <div class="periodical"> <em>IEEE Robotics and Automation Magazine</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2501.06566" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/11079769" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/RAM2025.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We propose the Cooperative Aerial Robot Inspection Challenge (CARIC), a simulation-based benchmark for motion planning algorithms in heterogeneous multi-UAV systems. CARIC features UAV teams with complementary sensors, realistic constraints, and evaluation metrics prioritizing inspection quality and efficiency. It offers a ready-to-use perception-control software stack and diverse scenarios to support the development and evaluation of task allocation and motion planning algorithms. Competitions using CARIC were held at IEEE CDC 2023 and the IROS 2024 Workshop on Multi-Robot Perception and Navigation, attracting innovative solutions from research teams worldwide. This paper examines the top three teams from CDC 2023, analyzing their exploration, inspection, and task allocation strategies while drawing insights into their performance across scenarios. The results highlight the task’s complexity and suggest promising research directions in cooperative multi-UAV systems. The simulation framework, including source code and detailed instructions, is publicly available at https://ntu-aris.github.io/caric.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">RAM2025</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cooperative Aerial Robot Inspection Challenge: A Benchmark for Heterogeneous Multi-UAV Planning and Lessons Learned}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cao, Muqing and Nguyen, Thien-Minh and Yuan, Shenghai and Anastasiou, Andreas and Zacharia, Angelos and Papaioannou, Savvas and Kolios, Panayiotis and Panayiotou, Christos G. and Polycarpou, Marios M. and Xu, Xinhang and Zhang, Mingjie and Gao, Fei and Zhou, Boyu and Chen, Ben M. and Xie, Lihua}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Magazine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/MRA.2025.3584341}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/RSTA2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="RSTA2025.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="papaioannou2025rolling" class="col-sm-8"> <div class="title">Rolling horizon coverage control with collaborative autonomous agents</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G Panayiotou, and Marios M Polycarpou </div> <div class="periodical"> <em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2504.05883" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://royalsocietypublishing.org/doi/10.1098/rsta.2024.0146" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/RSTA2025.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This work proposes a coverage controller that enables an aerial team of distributed autonomous agents to collaboratively generate non-myopic coverage plans over a rolling finite horizon, aiming to cover specific points on the surface area of a three-dimensional object of interest. The collaborative coverage problem, formulated as a distributed model predictive control problem, optimizes the agents’ motion and camera control inputs, while considering inter-agent constraints aiming at reducing work redundancy. The proposed coverage controller integrates constraints based on light-path propagation techniques to predict the parts of the object’s surface that are visible with regard to the agents’ future anticipated states. This work also demonstrates how complex, non-linear visibility assessment constraints can be converted into logical expressions that are embedded as binary constraints into a mixed-integer optimization framework. The proposed approach has been demonstrated through simulations and practical applications for inspecting buildings with unmanned aerial vehicles (UAVs).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">papaioannou2025rolling</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Rolling horizon coverage control with collaborative autonomous agents}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G and Polycarpou, Marios M}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{383}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2289}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Royal Society}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1098/rsta.2024.0146}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/TMC2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="TMC2025.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9894722" class="col-sm-8"> <div class="title">Jointly-optimized Trajectory Generation and Camera Control for 3D Coverage Planning</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2504.05887" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10925885" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/TMC2025.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This work proposes a jointly-optimized trajectory generation and camera control approach which allows an autonomous UAV agent, operating in 3D environments, to plan and execute coverage trajectories that maximally cover the surface area of a 3D object of interest. More specifically, the UAV’s kinematic and camera control inputs are jointly-optimized over a rolling finite planning horizon for the complete 3D coverage of the object of interest. The proposed controller integrates ray-tracing into the planning process in order to simulate the propagation of light-rays and thus determine the visible parts of the object through the UAV’s camera. Subsequently, this enables the generation of accurate look-ahead coverage trajectories. The coverage planning problem is formulated in this work as a rolling finite horizon optimal control problem, and solved with mixed integer programming techniques. Extensive real-world and synthetic experiments demonstrate the performance of the proposed approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9894722</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Mobile Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Jointly-optimized Trajectory Generation and Camera Control for 3D Coverage Planning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMC.2025.3551362}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/ICUAS2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ICUAS2025.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="JianlinICUAS25" class="col-sm-8"> <div class="title">VLM-RRT: Vision Language Model Guided RRT Search for Autonomous UAV Navigation</div> <div class="author"> Jianlin Ye, <em>Savvas Papaioannou</em>, and Panayiotis Kolios </div> <div class="periodical"> <em>In 2025 International Conference on Unmanned Aircraft Systems (ICUAS)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2505.23267" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/11007837" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/ICUAS25.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Path planning is a fundamental capability of autonomous Unmanned Aerial Vehicles (UAVs), enabling them to efficiently navigate toward a target region or explore complex environments while avoiding obstacles. Traditional path-planning methods, such as Rapidly-exploring Random Trees (RRT), have proven effective but often encounter significant challenges. These include high search space complexity, suboptimal path quality, and slow convergence, issues that are particularly problematic in high-stakes applications like disaster response, where rapid and efficient planning is critical. To address these limitations and enhance path-planning efficiency, we propose Vision Language Model RRT (VLM-RRT), a hybrid approach that integrates the pattern recognition capabilities of Vision Language Models (VLMs) with the path-planning strengths of RRT. By leveraging VLMs to provide initial directional guidance based on environmental snapshots, our method biases sampling toward regions more likely to contain feasible paths, significantly improving sampling efficiency and path quality. Extensive quantitative and qualitative experiments with various state-of-the-art VLMs demonstrate the effectiveness of this proposed approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">JianlinICUAS25</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ye, Jianlin and Papaioannou, Savvas and Kolios, Panayiotis}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2025 International Conference on Unmanned Aircraft Systems (ICUAS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{VLM-RRT: Vision Language Model Guided RRT Search for Autonomous UAV Navigation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{633-640}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICUAS65942.2025.11007837}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/ECC2025_3.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ECC2025_3.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="AnastasiouECC25" class="col-sm-8"> <div class="title">Multiple Target Tracking Using a UAV Swarm in Maritime Environments</div> <div class="author"> Andreas Anastasiou, <em>Savvas Papaioannou</em>, Panayiotis Kolios, and Christos G. Panayiotou </div> <div class="periodical"> <em>In 2025 European Control Conference (ECC)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2504.18153" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Nowadays, unmanned aerial vehicles (UAVs) are increasingly utilized in search and rescue missions, a trend driven by technological advancements, including enhancements in automation, avionics, and the reduced cost of electronics. In this work, we introduce a collaborative model predictive control (MPC) framework aimed at addressing the joint problem of guidance and state estimation for tracking multiple castaway targets with a fleet of autonomous UAV agents. We assume that each UAV agent is equipped with a camera sensor, which has a limited sensing range and is utilized for receiving noisy observations from multiple moving castaways adrift in maritime conditions. We derive a nonlinear mixed integer programming (NMIP) -based controller that facilitates the guidance of the UAVs by generating non-myopic trajectories within a receding planning horizon. These trajectories are designed to minimize the tracking error across multiple targets by directing the UAV fleet to locations expected to yield targets measurements, thereby minimizing the uncertainty of the estimated target states. Extensive simulation experiments validate the effectiveness of our proposed method in tracking multiple castaways in maritime environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AnastasiouECC25</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Anastasiou, Andreas and Papaioannou, Savvas and Kolios, Panayiotis and Panayiotou, Christos G.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2025 European Control Conference (ECC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multiple Target Tracking Using a UAV Swarm in Maritime Environments}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/ECC2025_2.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ECC2025_2.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="BourazasECC25" class="col-sm-8"> <div class="title">Adaptive Out-of-Control Point Pattern Detection in Sequential Random Finite Set Observations</div> <div class="author"> Konstantinos Bourazas, <em>Savvas Papaioannou</em>, and Panayiotis Kolios </div> <div class="periodical"> <em>In 2025 European Control Conference (ECC)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2506.23802" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ECC2025_2.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this work we introduce a novel adaptive anomaly detection framework specifically designed for monitoring sequential random finite set (RFS) observations. Our approach effectively distinguishes between in-control data (normal) and out-of-control data (anomalies) by detecting deviations from the expected statistical behavior of the process. The primary contributions of this study include the development of an innovative RFS-based framework that not only learns the normal behavior of the data-generating process online but also dynamically adapts to behavioral shifts to accurately identify abnormal point patterns. To achieve this, we introduce a new class of RFS-based posterior distributions, named Power Discounting Posteriors (PD), which facilitate adaptation to systematic changes in data while enabling anomaly detection of point pattern data through a novel predictive posterior density function. The effectiveness of the proposed approach is demonstrated by extensive qualitative and quantitative simulation experiments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BourazasECC25</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bourazas, Konstantinos and Papaioannou, Savvas and Kolios, Panayiotis}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2025 European Control Conference (ECC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adaptive Out-of-Control Point Pattern Detection in Sequential Random Finite Set Observations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/ECC2025_1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ECC2025_1.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="PapaioannouECC25" class="col-sm-8"> <div class="title">Data-Driven Predictive Planning and Control for Aerial 3D Inspection with Back-face Elimination</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Christos G Panayiotou, and Marios M Polycarpou </div> <div class="periodical"> <em>In 2025 European Control Conference (ECC)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2506.23781" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ECC2025_1.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Automated inspection with Unmanned Aerial Systems (UASs) is a transformative capability set to revolutionize various application domains. However, this task is inherently complex, as it demands the seamless integration of perception, planning, and control which existing approaches often treat separately. Moreover, it requires accurate long-horizon planning to predict action sequences, in contrast to many current techniques, which tend to be myopic. To overcome these limitations, we propose a 3D inspection approach that unifies perception, planning, and control within a single data-driven predictive control framework. Unlike traditional methods that rely on known UAS dynamic models, our approach requires only input-output data, making it easily applicable to off-the-shelf black-box UASs. Our method incorporates back-face elimination, a visibility determination technique from 3D computer graphics, directly into the control loop, thereby enabling the online generation of accurate, long-horizon 3D inspection trajectories.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PapaioannouECC25</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Panayiotou, Christos G and Polycarpou, Marios M}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2025 European Control Conference (ECC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Data-Driven Predictive Planning and Control for Aerial 3D Inspection with Back-face Elimination}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/icarcv24.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icarcv24.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="icarcv2024" class="col-sm-8"> <div class="title">Probabilistically Robust Trajectory Planning of Multiple Aerial Agents</div> <div class="author"> Christian Vitale, <em>Savvas Papaioannou</em>, Panayiotis Kolios, and Georgios Ellinas </div> <div class="periodical"> <em>In 2024 18th International Conference on Control, Automation, Robotics and Vision (ICARCV)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2409.12718" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10821544" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/icarcv24.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Current research on robust trajectory planning for autonomous agents aims to mitigate uncertainties arising from disturbances and modeling errors while ensuring guaranteed safety. Existing methods primarily utilize stochastic optimal control techniques with chance constraints to maintain a minimum distance among agents with a guaranteed probability. However, these approaches face challenges, such as the use of simplifying assumptions that result in linear system models or Gaussian disturbances, which limit their practicality in complex realistic scenarios. To address these limitations, this work introduces a novel probabilistically robust distributed controller enabling autonomous agents to plan safe trajectories, even under non-Gaussian uncertainty and nonlinear systems. Leveraging exact uncertainty propagation techniques based on mixed-trigonometric-polynomial moment propagation, this method transforms non-Gaussian chance constraints into deterministic ones, seamlessly integrating them into a distributed model predictive control framework solvable with standard optimization tools. Simulation results demonstrate the effectiveness of this technique, highlighting its ability to consistently handle various types of uncertainty, ensuring robust and accurate path planning in complex scenarios.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">icarcv2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vitale, Christian and Papaioannou, Savvas and Kolios, Panayiotis and Ellinas, Georgios}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 18th International Conference on Control, Automation, Robotics and Vision (ICARCV)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Probabilistically Robust Trajectory Planning of Multiple Aerial Agents}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{852-859}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICARCV63323.2024.10821544}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/icuas2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icuas2024.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="icuas2024" class="col-sm-8"> <div class="title">Automated Real-Time Inspection in Indoor and Outdoor 3D Environments with Cooperative Aerial Robots</div> <div class="author"> Andreas Anastasiou, Angelos Zacharia, <em>Savvas Papaioannou</em>, Panayiotis Kolios, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 2024 International Conference on Unmanned Aircraft Systems (ICUAS)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2404.12018" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10557006" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/icuas2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This work introduces a cooperative inspection system designed to efficiently control and coordinate a team of distributed heterogeneous UAV agents for the inspection of 3D structures in cluttered, unknown spaces. Our proposed approach employs a two-stage innovative methodology. Initially, it leverages the complementary sensing capabilities of the robots to cooperatively map the unknown environment. It then generates optimized, collision-free inspection paths, thereby ensuring comprehensive coverage of the structure’s surface area. The effectiveness of our system is demonstrated through qualitative and quantitative results from extensive Gazebo-based simulations that closely replicate real-world inspection scenarios, highlighting its ability to thoroughly inspect real-world-like 3D structures</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">icuas2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Anastasiou, Andreas and Zacharia, Angelos and Papaioannou, Savvas and Kolios, Panayiotis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 International Conference on Unmanned Aircraft Systems (ICUAS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automated Real-Time Inspection in Indoor and Outdoor 3D Environments with Cooperative Aerial Robots}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICUAS60882.2024.10557006}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/wcci2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wcci2024.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wcci2024" class="col-sm-8"> <div class="title">Synergising Human-like Responses and Machine Intelligence for Planning in Disaster Response</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 2024 International Joint Conference on Neural Networks (IJCNN)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2404.09877" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10651466" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/wcci2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In the rapidly changing environments of disaster response, planning and decision-making for autonomous agents involve complex and interdependent choices. Although recent advancements have improved traditional artificial intelligence (AI) approaches, they often struggle in such settings, particularly when applied to agents operating outside their well-defined training parameters. To address these challenges, we propose an attention-based cognitive architecture inspired by Dual Process Theory (DPT). This framework integrates, in an online fashion, rapid yet heuristic (human-like) responses (System 1) with the slow but optimized planning capabilities of machine intelligence (System 2). We illustrate how a supervisory controller can dynamically determine in real-time the engagement of either system to optimize mission objectives by assessing their performance across a number of distinct attributes. Evaluated for trajectory planning in dynamic environments, our framework demonstrates that this synergistic integration effectively manages complex tasks by optimizing multiple mission objectives.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wcci2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 International Joint Conference on Neural Networks (IJCNN)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Synergising Human-like Responses and Machine Intelligence for Planning in Disaster Response}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-8}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IJCNN60899.2024.10651466}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/safeprocess2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="safeprocess2024.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="safeprocess2024" class="col-sm-8"> <div class="title">Hierarchical Fault-Tolerant Coverage Control for an Autonomous Aerial Agent</div> <div class="author"> <em>Savvas Papaioannou</em>, Christian Vitale, Panayiotis Kolios, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 12th IFAC Symposium on Fault Detection, Supervision and Safety for Technical Processes (SAFEPROCESS 2024)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2404.09838" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S2405896324003574" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/safeprocess2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Fault-tolerant coverage control involves determining a trajectory that enables an autonomous agent to cover specific points of interest, even in the presence of actuation and/or sensing faults. In this work, the agent encounters control inputs that are erroneous; specifically, its nominal controls inputs are perturbed by stochastic disturbances, potentially disrupting its intended operation. Existing techniques have focused on deterministically bounded disturbances or relied on the assumption of Gaussian disturbances, whereas non-Gaussian disturbances have been primarily been tackled via scenario-based stochastic control methods. However, the assumption of Gaussian disturbances is generally limited to linear systems, and scenario-based methods can become computationally prohibitive. To address these limitations, we propose a hierarchical coverage controller that integrates mixed-trigonometric-polynomial moment propagation to propagate non-Gaussian disturbances through the agent’s nonlinear dynamics. Specifically, the first stage generates an ideal reference plan by optimising the agent’s mobility and camera control inputs. The second-stage fault-tolerant controller then aims to follow this reference plan, even in the presence of erroneous control inputs caused by non-Gaussian disturbances. This is achieved by imposing a set of deterministic constraints on the moments of the system’s uncertain states.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">safeprocess2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hierarchical Fault-Tolerant Coverage Control for an Autonomous Aerial Agent}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Vitale, Christian and Kolios, Panayiotis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{12th IFAC Symposium on Fault Detection, Supervision and Safety for Technical Processes (SAFEPROCESS 2024)}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{58}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{532-537}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2405-8963}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.ifacol.2024.07.273}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/tsmc23.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tsmc23.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10044164" class="col-sm-8"> <div class="title">Distributed Search Planning in 3-D Environments With a Dynamically Varying Number of Agents</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>IEEE Transactions on Systems, Man, and Cybernetics: Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2304.08932" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10044164" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/tsmc23.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this work, a novel distributed search-planning framework is proposed, where a dynamically varying team of autonomous agents cooperate in order to search multiple objects of interest in three-dimension (3-D). It is assumed that the agents can enter and exit the mission space at any point in time, and as a result the number of agents that actively participate in the mission varies over time. The proposed distributed search-planning framework takes into account the agent dynamical and sensing model, and the dynamically varying number of agents, and utilizes model predictive control (MPC) to generate cooperative search trajectories over a finite rolling planning horizon. This enables the agents to adapt their decisions on-line while considering the plans of their peers, maximizing their search planning performance, and reducing the duplication of work.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10044164</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Systems, Man, and Cybernetics: Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Distributed Search Planning in 3-D Environments With a Dynamically Varying Number of Agents}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{53}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4117-4130}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TSMC.2023.3240023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/taes22.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="taes22.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9861757" class="col-sm-8"> <div class="title">Integrated Guidance and Gimbal Control for Coverage Planning With Visibility Constraints</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>IEEE Transactions on Aerospace and Electronic Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.12999" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9861757" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/taes22.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Coverage path planning with unmanned aerial vehicles (UAVs) is a core task for many services and applications including search and rescue, precision agriculture, infrastructure inspection and surveillance. This work proposes an integrated guidance and gimbal control coverage path planning (CPP) approach, in which the mobility and gimbal inputs of an autonomous UAV agent are jointly controlled and optimized to achieve full coverage of a given object of interest, according to a specified set of optimality criteria. The proposed approach uses a set of visibility constraints to integrate the physical behavior of sensor signals (i.e., camera-rays) into the coverage planning process, thus generating optimized coverage trajectories that take into account which parts of the scene are visible through the agent’s camera at any point in time. The integrated guidance and gimbal control CPP problem is posed in this work as a constrained optimal control problem which is then solved using mixed integer programming (MIP) optimization. Extensive numerical experiments demonstrate the effectiveness of the proposed approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9861757</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Aerospace and Electronic Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Integrated Guidance and Gimbal Control for Coverage Planning With Visibility Constraints}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{59}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1276-1291}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TAES.2022.3199196}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/cdc2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cdc2023.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="cdc2023" class="col-sm-8"> <div class="title">Cooperative Receding Horizon 3D Coverage Control with a Team of Networked Aerial Agents</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 2023 IEEE 62st Conference on Decision and Control (CDC)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2401.15674" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10383310" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/CDC2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This work proposes a receding horizon coverage control approach which allows multiple autonomous aerial agents to work cooperatively in order cover the total surface area of a 3D object of interest. The cooperative coverage problem which is posed in this work as an optimal control problem, jointly optimizes the agents’ kinematic and camera control inputs, while considering coupling constraints amongst the team of agents which aim at minimizing the duplication of work. To generate look-ahead coverage trajectories over a finite planning horizon, the proposed approach integrates visibility constraints into the proposed coverage controller in order to determine the visible part of the object with respect to the agents’ future states. In particular, we show how non-linear and non-convex visibility determination constraints can be transformed into logical constraints which can easily be embedded into a mixed integer optimization program.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cdc2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 IEEE 62st Conference on Decision and Control (CDC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cooperative Receding Horizon 3D Coverage Control with a Team of Networked Aerial Agents}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4399-4404}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CDC49753.2023.10383310}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/icuas2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icuas2023.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10156482" class="col-sm-8"> <div class="title">Unscented Optimal Control for 3D Coverage Planning with an Autonomous UAV Agent</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 2023 International Conference on Unmanned Aircraft Systems (ICUAS)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2306.17588" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10156482" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/icuas2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We propose a novel probabilistically robust controller for the guidance of an unmanned aerial vehicle (UAV) in coverage planning missions, which can simultaneously optimize both the UAV’s motion, and camera control inputs for the 3D coverage of a given object of interest. Specifically, the coverage planning problem is formulated in this work as an optimal control problem with logical constraints to enable the UAV agent to jointly: a) select a series of discrete camera field-of-view states which satisfy a set of coverage constraints, and b) optimize its motion control inputs according to a specified mission objective. We show how this hybrid optimal control problem can be solved with standard optimization tools by converting the logical expressions in the constraints into equality/inequality constraints involving only continuous variables. Finally, probabilistic robustness is achieved by integrating the unscented transformation to the proposed controller, thus enabling the design of robust open-loop coverage plans which take into account the future posterior distribution of the UAV’s state inside the planning horizon.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10156482</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 International Conference on Unmanned Aircraft Systems (ICUAS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Unscented Optimal Control for 3D Coverage Planning with an Autonomous UAV Agent}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{703-712}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICUAS57906.2023.10156482}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/med2023_s.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="med2023_s.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10185768" class="col-sm-8"> <div class="title">Joint Estimation and Control for Multi-Target Passive Monitoring with an Autonomous UAV Agent</div> <div class="author"> <em>Savvas Papaioannou</em>, Christos Laoudias, Panayiotis Kolios, Theocharis Theocharides, and Christos G. Panayiotou </div> <div class="periodical"> <em>In 2023 31st Mediterranean Conference on Control and Automation (MED)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2307.06633" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10185768" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/med2023_s.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This work considers the problem of passively monitoring multiple moving targets with a single unmanned aerial vehicle (UAV) agent equipped with a direction-finding radar. This is in general a challenging problem due to the unobservability of the target states, and the highly non-linear measurement process. In addition to these challenges, in this work we also consider: a) environments with multiple obstacles where the targets need to be tracked as they manoeuvre through the obstacles, and b) multiple false-alarm measurements caused by the cluttered environment. To address these challenges we first design a model predictive guidance controller which is used to plan hypothetical target trajectories over a rolling finite planning horizon. We then formulate a joint estimation and control problem where the trajectory of the UAV agent is optimized to achieve optimal multi-target monitoring.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10185768</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Laoudias, Christos and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 31st Mediterranean Conference on Control and Automation (MED)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Joint Estimation and Control for Multi-Target Passive Monitoring with an Autonomous UAV Agent}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{176-181}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/MED59994.2023.10185768}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/med2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="med2023.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10185881" class="col-sm-8"> <div class="title">Distributed Control for 3D Inspection using Multi-UAV Systems</div> <div class="author"> Angelos Zacharia, <em>Savvas Papaioannou</em>, Panayiotis Kolios, and Christos Panayiotou </div> <div class="periodical"> <em>In 2023 31st Mediterranean Conference on Control and Automation (MED)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2409.13302" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10185881" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/med2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Cooperative control of multi-UAV systems has attracted substantial research attention due to its significance in various application sectors such as emergency response, search and rescue missions, and critical infrastructure inspection. This paper proposes a distributed control algorithm to generate collision-free trajectories that drive the multi-UAV system to completely inspect a set of 3D points on the surface of an object of interest. The objective of the UAVs is to cooperatively inspect the object of interest in the minimum amount of time. Extensive numerical simulations for a team of quadrotor UAVs inspecting a real 3D structure illustrate the validity and effectiveness of the proposed approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10185881</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zacharia, Angelos and Papaioannou, Savvas and Kolios, Panayiotis and Panayiotou, Christos}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 31st Mediterranean Conference on Control and Automation (MED)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Distributed Control for 3D Inspection using Multi-UAV Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{164-169}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/MED59994.2023.10185881}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/ecc2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ecc2023.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10178187" class="col-sm-8"> <div class="title">Model Predictive Control For Multiple Castaway Tracking with an Autonomous Aerial Agent</div> <div class="author"> Andreas Anastasiou, <em>Savvas Papaioannou</em>, Panayiotis Kolios, and Christos G. Panayiotou </div> <div class="periodical"> <em>In 2023 European Control Conference (ECC)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2409.13305" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10178187" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/ecc2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Over the past few years, a plethora of advancements in Unmanned Areal Vehicle (UAV) technology has paved the way for UAV-based Search and Rescue (SAR) operations with transformative impact to the outcome of critical life-saving missions. This paper dives into the challenging task of multiple castaway tracking using an autonomous UAV agent. Leveraging on the computing power of the modern embedded devices, we propose a Model Predictive Control (MPC) framework for tracking multiple castaways assumed to drift afloat in the aftermath of a maritime accident. We consider a stationary radar sensor that is responsible for signaling the search mission by providing noisy measurements of each castaway’s initial state. The UAV agent aims at detecting and tracking the moving targets with its equipped onboard camera sensor that has limited sensing range. In this work, we also experimentally determine the probability of target detection from real-world data by training and evaluating various Convolutional Neural Networks (CNNs). Extensive qualitative and quantitative evaluations demonstrate the performance of the proposed approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10178187</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Anastasiou, Andreas and Papaioannou, Savvas and Kolios, Panayiotis and Panayiotou, Christos G.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 European Control Conference (ECC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Model Predictive Control For Multiple Castaway Tracking with an Autonomous Aerial Agent}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-8}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.23919/ECC57647.2023.10178187}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/tmc22_s.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tmc22_s.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9894723" class="col-sm-8"> <div class="title">Distributed Estimation and Control for Jamming an Aerial Target With Multiple Agents</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, and Georgios Ellinas </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.13919" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9894722" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/tmc22_s.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This work proposes a distributed estimation and control approach in which a team of aerial agents equipped with radio jamming devices collaborate in order to intercept and concurrently track-and-jam a malicious target, while at the same time minimizing the induced jamming interference amongst the team. Specifically, it is assumed that the malicious target maneuvers in 3D space, avoiding collisions with obstacles and other 3D structures in its way, according to a stochastic dynamical model. Based on this, a track-and-jam control approach is proposed which allows a team of distributed aerial agents to decide their control actions online, over a finite planning horizon, to achieve uninterrupted radio-jamming and tracking of the malicious target, in the presence of jamming interference constraints. The proposed approach is formulated as a distributed model predictive control (MPC) problem and is solved using mixed integer quadratic programming (MIQP). Extensive evaluation of the system’s performance validates the applicability of the proposed approach in challenging scenarios with uncertain target dynamics, noisy measurements, and in the presence of obstacles.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9894723</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Ellinas, Georgios}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Mobile Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Distributed Estimation and Control for Jamming an Aerial Target With Multiple Agents}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-15}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMC.2022.3207589}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/JINT22.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="JINT22.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="vitale2022autonomous" class="col-sm-8"> <div class="title">Autonomous 4D Trajectory Planning for Dynamic and Flexible Air Traffic Management</div> <div class="author"> Christian Vitale, <em>Savvas Papaioannou</em>, Panayiotis Kolios, and Georgios Ellinas </div> <div class="periodical"> <em>Journal of Intelligent &amp; Robotic Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/article/10.1007/s10846-022-01715-z" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/JINT22.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>With an ever increasing number of unmanned aerial vehicles (UAVs) in flight, there is a pressing need for scalable and dynamic air traffic management solutions that ensure efficient use of the airspace while maintaining safety and avoiding mid-air collisions. To address this need, a novel framework is developed for computing optimized 4D trajectories for UAVs that ensure dynamic and flexible use of the airspace, while maximizing the available capacity through the minimization of the aggregate traveling times. Specifically, a network manager (NM) is utilized that considers UAV requests (including start/target locations) and addresses inherent mobility uncertainties using a linear-Gaussian system, to compute efficient and safe trajectories. Through the proposed framework, a family of mathematical programming problems is derived to compute control profiles for both distributed and centralized implementations. Extensive simulation results are presented to demonstrate the applicability of the proposed framework to maximize air traffic throughput under probabilistic collision avoidance guarantees.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">vitale2022autonomous</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Autonomous 4D Trajectory Planning for Dynamic and Flexible Air Traffic Management}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vitale, Christian and Papaioannou, Savvas and Kolios, Panayiotis and Ellinas, Georgios}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Intelligent \&amp; Robotic Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{106}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10846-022-01715-z}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/TMC22.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="TMC22.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9363641" class="col-sm-8"> <div class="title">Multi-Agent Coordinated Close-in Jamming for Disabling a Rogue Drone</div> <div class="author"> Panayiota Valianti, <em>Savvas Papaioannou</em>, Panayiotis Kolios, and Georgios Ellinas </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9363641" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Drones, including remotely piloted aircraft or unmanned aerial vehicles, have become extremely appealing over the recent years, with a multitude of applications and usages. However, they can potentially present major threats for security and public safety, especially when they fly across critical infrastructures and public spaces. This work investigates a novel counter-drone solution by proposing a multi-agent framework in which a team of pursuer drones cooperate in order to track and jam a rogue drone. Within the proposed framework, a joint mobility and power control solution is developed to optimize the respective decisions of each cooperating agent in order to best track and intercept the moving rogue drone. Both centralized and distributed variants of the joint optimization problem are developed and extensive simulations are conducted to evaluate the performance of the problem variants and to demonstrate the effectiveness of the proposed solution.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9363641</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Valianti, Panayiota and Papaioannou, Savvas and Kolios, Panayiotis and Ellinas, Georgios}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Mobile Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-Agent Coordinated Close-in Jamming for Disabling a Rogue Drone}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{21}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3700-3717}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMC.2021.3062225}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/cdc2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cdc2022.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9992360" class="col-sm-8"> <div class="title">Integrated Ray-Tracing and Coverage Planning Control using Reinforcement Learning</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 2022 IEEE 61st Conference on Decision and Control (CDC)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2304.09631" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9992360" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/cdc2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this work we propose a coverage planning control approach which allows a mobile agent, equipped with a controllable sensor (i.e., a camera) with limited sensing domain (i.e., finite sensing range and angle of view), to cover the surface area of an object of interest. The proposed approach integrates ray-tracing into the coverage planning process, thus allowing the agent to identify which parts of the scene are visible at any point in time. The problem of integrated ray-tracing and coverage planning control is first formulated as a constrained optimal control problem (OCP), which aims at determining the agent’s optimal control inputs over a finite planning horizon, that minimize the coverage time. Efficiently solving the resulting OCP is however very challenging due to non-convex and nonlinear visibility constraints. To overcome this limitation, the problem is converted into a Markov decision process (MDP) which is then solved using reinforcement learning. In particular, we show that a controller which follows an optimal control law can be learned using off-policy temporal-difference control (i.e., Q-learning). Extensive numerical experiments demonstrate the effectiveness of the proposed approach for various configurations of the agent and the object of interest.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9992360</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 IEEE 61st Conference on Decision and Control (CDC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Integrated Ray-Tracing and Coverage Planning Control using Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7200-7207}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CDC51059.2022.9992360}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/icuas2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icuas2022.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9836051" class="col-sm-8"> <div class="title">UAV-based Receding Horizon Control for 3D Inspection Planning</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 2022 International Conference on Unmanned Aircraft Systems (ICUAS)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2304.10201" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9836051" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/icuas2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Nowadays, unmanned aerial vehicles or UAVs are being used for a wide range of tasks, including infrastructure inspection, automated monitoring and coverage. This paper investigates the problem of 3D inspection planning with an autonomous UAV agent which is subject to dynamical and sensing constraints. We propose a receding horizon 3D inspection planning control approach for generating optimal trajectories which enable an autonomous UAV agent to inspect a finite number of feature-points scattered on the surface of a cuboid-like structure of interest. The inspection planning problem is formulated as a constrained open-loop optimal control problem and is solved using mixed integer programming (MIP) optimization. Quantitative and qualitative evaluation demonstrates the effectiveness of the proposed approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9836051</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 International Conference on Unmanned Aircraft Systems (ICUAS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{UAV-based Receding Horizon Control for 3D Inspection Planning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1121-1130}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICUAS54217.2022.9836051}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/JINT21.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="JINT21.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="papaioannou2021towards" class="col-sm-8"> <div class="title">Towards Automated 3D Search Planning for Emergency Response Missions</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G Panayiotou, and Marios M Polycarpou </div> <div class="periodical"> <em>Journal of Intelligent &amp; Robotic Systems</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2304.03570" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/article/10.1007/s10846-021-01449-4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/JINT21.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The ability to efficiently plan and execute automated and precise search missions using unmanned aerial vehicles (UAVs) during emergency response situations is imperative. Precise navigation between obstacles and time-efficient searching of 3D structures and buildings are essential for locating survivors and people in need in emergency response missions. In this work we address this challenging problem by proposing a unified search planning framework that automates the process of UAV-based search planning in 3D environments. Specifically, we propose a novel search planning framework which enables automated planning and execution of collision-free search trajectories in 3D by taking into account low-level mission constrains (e.g., the UAV dynamical and sensing model), mission objectives (e.g., the mission execution time and the UAV energy efficiency) and user-defined mission specifications (e.g., the 3D structures to be searched and minimum detection probability constraints). The capabilities and performance of the proposed approach are demonstrated through extensive simulated 3D search scenarios.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">papaioannou2021towards</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Towards Automated 3D Search Planning for Emergency Response Missions}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G and Polycarpou, Marios M}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Intelligent \&amp; Robotic Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{103}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10846-021-01449-4}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/JIOT21.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="JIOT21.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9406813" class="col-sm-8"> <div class="title">Deep Reinforcement Learning Multi-UAV Trajectory Control for Target Tracking</div> <div class="author"> Jiseon Moon, <em>Savvas Papaioannou</em>, Christos Laoudias, Panayiotis Kolios, and Sunwoo Kim </div> <div class="periodical"> <em>IEEE Internet of Things Journal</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9406813" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/J_IoT.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this article, we propose a novel deep reinforcement learning (DRL) approach for controlling multiple unmanned aerial vehicles (UAVs) with the ultimate purpose of tracking multiple first responders (FRs) in challenging 3-D environments in the presence of obstacles and occlusions. We assume that the UAVs receive noisy distance measurements from the FRs which are of two types, i.e., Line of Sight (LoS) and non-LoS (NLoS) measurements and which are used by the UAV agents in order to estimate the state (i.e., position) of the FRs. Subsequently, the proposed DRL-based controller selects the optimal joint control actions according to the Cramér–Rao lower bound (CRLB) of the joint measurement likelihood function to achieve high tracking performance. Specifically, the optimal UAV control actions are quantified by the proposed reward function, which considers both the CRLB of the entire system and each UAV’s individual contribution to the system, called global reward and difference reward, respectively. Since the UAVs take actions that reduce the CRLB of the entire system, tracking accuracy is improved by ensuring the reception of high quality LoS measurements with high probability. Our simulation results show that the proposed DRL-based UAV controller provides a highly accurate target tracking solution with a very low runtime cost.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9406813</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Moon, Jiseon and Papaioannou, Savvas and Laoudias, Christos and Kolios, Panayiotis and Kim, Sunwoo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Internet of Things Journal}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep Reinforcement Learning Multi-UAV Trajectory Control for Target Tracking}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{15441-15455}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/JIOT.2021.3073973}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/tcns21.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tcns21.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9262008" class="col-sm-8"> <div class="title">A Cooperative Multiagent Probabilistic Framework for Search and Track Missions</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>IEEE Transactions on Control of Network Systems</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.10723" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9262008" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/tcns21.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this work, a robust and scalable cooperative multiagent searching and tracking (SAT) framework is proposed. Specifically, we study the problem of cooperative SAT of multiple moving targets by a group of autonomous mobile agents with limited sensing capabilities. We assume that the actual number of targets present is not known a priori and that target births/deaths can occur anywhere inside the surveillance region; thus efficient search strategies are required to detect and track as many targets as possible. To address the aforementioned challenges, we recursively compute and propagate in time the SAT density. Using the SAT density, we then develop decentralized cooperative look-ahead strategies for efficient SAT of an unknown number of targets inside a bounded surveillance area.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9262008</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Control of Network Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Cooperative Multiagent Probabilistic Framework for Search and Track Missions}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{847-858}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TCNS.2020.3038843}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/iros2021.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iros2021.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9636065" class="col-sm-8"> <div class="title">Downing a Rogue Drone with a Team of Aerial Radio Signal Jammers</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, and Georgios Ellinas </div> <div class="periodical"> <em>In 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2303.09884" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9636065" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/iros2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This work proposes a novel distributed control framework in which a team of pursuer agents equipped with a radio jamming device cooperate in order to track and radio-jam a rogue target in 3D space, with the ultimate purpose of disrupting its communication and navigation circuitry. The target evolves in 3D space according to a stochastic dynamical model and it can appear and disappear from the surveillance area at random times. The pursuer agents cooperate in order to estimate the probability of target existence and its spatial density from a set of noisy measurements in the presence of clutter. Additionally, the proposed control framework allows a team of pursuer agents to optimally choose their radio transmission levels and their mobility control actions in order to ensure uninterrupted radio jamming to the target, as well as to avoid the jamming interference among the team of pursuer agents. Extensive simulation analysis of the system’s performance validates the applicability of the proposed approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9636065</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Ellinas, Georgios}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Downing a Rogue Drone with a Team of Aerial Radio Signal Jammers}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2555-2562}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS51168.2021.9636065}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/icuas2021.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icuas2021.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9476869" class="col-sm-8"> <div class="title">3D Trajectory Planning for UAV-based Search Missions: An Integrated Assessment and Search Planning Approach</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 2021 International Conference on Unmanned Aircraft Systems (ICUAS)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.12587" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9476869" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/icuas2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The ability to efficiently plan and execute search missions in challenging and complex environments during natural and man-made disasters is imperative. In many emergency situations, precise navigation between obstacles and time-efficient searching around 3D structures is essential for finding survivors. In this work we propose an integrated assessment and search planning approach which allows an autonomous UAV (unmanned aerial vehicle) agent to plan and execute collision-free search trajectories in 3D environments. More specifically, the proposed search-planning framework aims to integrate and automate the first two phases (i.e., the assessment phase and the search phase) of a traditional search-and-rescue (SAR) mission. In the first stage, termed assessment-planning we aim to find a high-level assessment plan which the UAV agent can execute in order to visit a set of points of interest. The generated plan of this stage guides the UAV to fly over the objects of interest thus providing a first assessment of the situation at hand. In the second stage, termed search-planning, the UAV trajectory is further fine-tuned to allow the UAV to search in 3D (i.e., across all faces) the objects of interest for survivors. The performance of the proposed approach is demonstrated through extensive simulation analysis.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9476869</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 International Conference on Unmanned Aircraft Systems (ICUAS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{3D Trajectory Planning for UAV-based Search Missions: An Integrated Assessment and Search Planning Approach}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{517-526}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICUAS51884.2021.9476869}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/tmc18.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tmc18.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="8736404" class="col-sm-8"> <div class="title">Jointly-Optimized Searching and Tracking with Random Finite Sets</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.01845" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/8736404" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/tmc18.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this paper, we investigate the problem of joint searching and tracking of multiple mobile targets by a group of mobile agents. The targets appear and disappear at random times inside a surveillance region and their positions are random and unknown. The agents have limited sensing range and receive noisy measurements from the targets. A decision and control problem arises, where the mode of operation (i.e., search or track) as well as the mobility control action for each agent, at each time instance, must be determined so that the collective goal of searching and tracking is achieved. We build our approach upon the theory of random finite sets (RFS) and we use Bayesian multi-object stochastic filtering to simultaneously estimate the time-varying number of targets and their states from a sequence of noisy measurements. We formulate the above problem as a non-linear binary program (NLBP) and show that it can be approximated by a genetic algorithm. Finally, to study the effectiveness and performance of the proposed approach we have conducted extensive simulation experiments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">8736404</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Mobile Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Jointly-Optimized Searching and Tracking with Random Finite Sets}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{19}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2374-2391}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMC.2019.2922133}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/icuas2020.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icuas2020.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9213937" class="col-sm-8"> <div class="title">Coordinated CRLB-based Control for Tracking Multiple First Responders in 3D Environments</div> <div class="author"> <em>Savvas Papaioannou</em>, Sungjin Kim, Christos Laoudias, Panayiotis Kolios, Sunwoo Kim, Theocharis Theocharides, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Christos Panayiotou, Marios Polycarpou' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In 2020 International Conference on Unmanned Aircraft Systems (ICUAS)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9213937" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>In this paper we study the problem of tracking a team of first responders with a fleet of autonomous mobile flying agents, operating in 3D environments. We assume that the first responders exhibit stochastic dynamics and evolve inside challenging environments with obstacles and occlusions. As a result, the mobile agents probabilistically receive noisy line-of-sight (LoS), as well as non-line-of-sight (NLoS) range measurements from the first responders. In this work, we propose a novel estimation (i.e., estimating the position of multiple first responders over time) and control (i.e., controlling the movement of the agents) framework based on the Cramér-Rao lower bound (CRLB). More specifically, we analytically derive the CRLB of the measurement likelihood function which we use as a control criterion to select the optimal joint control actions over all agents, thus achieving optimized tracking performance. The effectiveness of the proposed multi-agent multi-target estimation and control framework is demonstrated through an extensive simulation analysis.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9213937</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kim, Sungjin and Laoudias, Christos and Kolios, Panayiotis and Kim, Sunwoo and Theocharides, Theocharis and Panayiotou, Christos and Polycarpou, Marios}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2020 International Conference on Unmanned Aircraft Systems (ICUAS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Coordinated CRLB-based Control for Tracking Multiple First Responders in 3D Environments}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1475-1484}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICUAS48674.2020.9213937}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/globecom.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="globecom.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9322489" class="col-sm-8"> <div class="title"> Multi-Agent Coordinated Interception of Multiple Rogue Drones</div> <div class="author"> Panayiota Valianti, <em>Savvas Papaioannou</em>, Panayiotis Kolios, and Georgios Ellinas </div> <div class="periodical"> <em>In 2020 IEEE Global Communications Conference (GLOBECOM)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9322489" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Over the last few years there has been an unprecedented interest in unmanned aerial vehicles (UAVs). However, drones potentially pose great threats to security and public safety, especially when their malicious use involves critical infrastructures and public spaces. This work proposes a multiagent counter-drone system where a team of pursuer drones cooperate in order to track and jam multiple rogue drones. Specifically, a cooperative multi-agent approach is proposed in which the best joint mobility and power control actions of each agent are chosen so that the rogue drones are optimally tracked and jammed over time. Two variants of the joint optimization problem are developed and extensive simulations are conducted so as to evaluate the performance of the proposed approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9322489</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Valianti, Panayiota and Papaioannou, Savvas and Kolios, Panayiotis and Ellinas, Georgios}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2020 IEEE Global Communications Conference (GLOBECOM)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ Multi-Agent Coordinated Interception of Multiple Rogue Drones}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/GLOBECOM42002.2020.9322489}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/IROS2020.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="IROS2020.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9340835" class="col-sm-8"> <div class="title">Cooperative Simultaneous Tracking and Jamming for Disabling a Rogue Drone</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.07575" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9340835" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/IROS2020.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This work investigates the problem of simultaneous tracking and jamming of a rogue drone in 3D space with a team of cooperative unmanned aerial vehicles (UAVs). We propose a decentralized estimation, decision and control framework in which a team of UAVs cooperate in order to a) optimally choose their mobility control actions that result in accurate target tracking and b) select the desired transmit power levels which cause uninterrupted radio jamming and thus ultimately disrupt the operation of the rogue drone. The proposed decision and control framework allows the UAVs to reconfigure themselves in 3D space such that the cooperative simultaneous tracking and jamming (CSTJ) objective is achieved; while at the same time ensures that the unwanted inter-UAV jamming interference caused during CSTJ is kept below a specified critical threshold. Finally, we formulate this problem under challenging conditions i.e., uncertain dynamics, noisy measurements and false alarms. Extensive simulation experiments illustrate the performance of the proposed approach</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9340835</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cooperative Simultaneous Tracking and Jamming for Disabling a Rogue Drone}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7919-7926}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS45743.2020.9340835}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/cdc2019.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cdc2019.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9029236" class="col-sm-8"> <div class="title">Decentralized Search and Track with Multiple Autonomous Agents</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 2019 IEEE 58th Conference on Decision and Control (CDC)</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.00515" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/9029236" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/cdc2019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this paper we study the problem of cooperative searching and tracking (SAT) of multiple moving targets with a group of autonomous mobile agents that exhibit limited sensing capabilities. We assume that the actual number of targets is not known a priori and that target births/deaths can occur anywhere inside the surveillance region. For this reason efficient search strategies are required to detect and track as many targets as possible. To address the aforementioned challenges we augment the classical Probability Hypothesis Density (PHD) filter with the ability to propagate in time the search density in addition to the target density. Based on this, we develop decentralized cooperative look-ahead strategies for efficient searching and tracking of an unknown number of targets inside a bounded surveillance area. The performance of the proposed approach is demonstrated through simulation experiments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9029236</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 IEEE 58th Conference on Decision and Control (CDC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Decentralized Search and Track with Multiple Autonomous Agents}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{909-915}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CDC40024.2019.9029236}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/icuas2019.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icuas2019.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="8797831" class="col-sm-8"> <div class="title">Probabilistic Search and Track with Multiple Mobile Agents</div> <div class="author"> <em>Savvas Papaioannou</em>, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou, and Marios M. Polycarpou </div> <div class="periodical"> <em>In 2019 International Conference on Unmanned Aircraft Systems (ICUAS)</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.00518" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/8797831" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/icuas19.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this paper we are interested in the task of searching and tracking multiple moving targets in a bounded surveillance area with a group of autonomous mobile agents. More specifically, we assume that targets can appear and disappear at random times inside the surveillance region and their positions are random and unknown. The agents have a limited sensing range, and due to sensor imperfections they receive noisy measurements from the targets. In this work we utilize the theory of random finite sets (RFS) to capture the uncertainty in the time-varying number of targets and their states and we propose a decision and control framework, in which the mode of operation (i.e. search or track) as well as the mobility control action for each agent, at each time instance, are determined so that the collective goal of searching and tracking is achieved. Extensive simulation results demonstrate the effectiveness and performance of the proposed solution.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">8797831</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G. and Polycarpou, Marios M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 International Conference on Unmanned Aircraft Systems (ICUAS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Probabilistic Search and Track with Multiple Mobile Agents}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{253-262}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICUAS.2019.8797831}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/TMC2016.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="TMC2016.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="7576696" class="col-sm-8"> <div class="title">Tracking People in Highly Dynamic Industrial Environments</div> <div class="author"> <em>Savvas Papaioannou</em>, Andrew Markham, and Niki Trigoni </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.00503" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/7576696" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/TMC2016.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>To date, the majority of positioning systems have been designed to operate within environments that have a long-term stable macro-structure with potential small-scale dynamics. These assumptions allow the existing positioning systems to produce and utilize stable maps. However, in highly dynamic industrial settings these assumptions are no longer valid and the task of tracking people is more challenging due to the rapid large-scale changes in structure. In this paper, we propose a novel positioning system for tracking people in highly dynamic industrial environments, such as construction sites. The proposed system leverages the existing CCTV camera infrastructure found in many industrial settings along with radio and inertial sensors within each worker’s mobile phone to accurately track multiple people. This multi-target multi-sensor tracking framework also allows our system to use cross-modality training in order to deal with the environment dynamics. In particular, we show how our system uses cross-modality training in order to automatically keep track environmental changes (i.e., new walls) by utilizing occlusion maps. In addition, we show how these maps can be used in conjunction with social forces to accurately predict human motion and increase the tracking accuracy. We have conducted extensive real-world experiments in a construction site showing significant accuracy improvement via cross-modality training and the use of social forces.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">7576696</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Markham, Andrew and Trigoni, Niki}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Mobile Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Tracking People in Highly Dynamic Industrial Environments}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2351-2365}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMC.2016.2613523}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/ipsn2016.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ipsn2016.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="IPSN2016" class="col-sm-8"> <div class="title">Poster Abstract: Efficient Visual Positioning with Adaptive Parameter Learning</div> <div class="author"> Hongkai Wen, Sen Wang, Ronnie Clark, <em>Savvas Papaioannou</em>, and Niki Trigoni </div> <div class="periodical"> <em>In 2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/7460701" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/IPSN2016.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Positioning with vision sensors is gaining its popularity, since it is more accurate, and requires much less bootstrapping and training effort. However, one of the major limitations of the existing solutions is the expensive visual processing pipeline: on resource-constrained mobile devices, it could take up to tens of seconds to process one frame. To address this, we propose a novel learning algorithm, which adaptively discovers the place dependent parameters for visual processing, such as which parts of the scene are more informative, and what kind of visual elements one would expect, as it is employed more and more by the users in a particular setting. With such meta-information, our positioning system dynamically adjust its behaviour, to localise the users with minimum effort. Preliminary results show that the proposed algorithm can reduce the cost on visual processing significantly, and achieve sub-metre positioning accuracy.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">IPSN2016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wen, Hongkai and Wang, Sen and Clark, Ronnie and Papaioannou, Savvas and Trigoni, Niki}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Poster Abstract: Efficient Visual Positioning with Adaptive Parameter Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-2}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IPSN.2016.7460701}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/sensys.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sensys.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1145/2809695.2809712" class="col-sm-8"> <div class="title">Accurate Positioning via Cross-Modality Training</div> <div class="author"> <em>Savvas Papaioannou</em>, Hongkai Wen, Zhuoling Xiao, Andrew Markham, and Niki Trigoni </div> <div class="periodical"> <em>In Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems (SenSys)</em>, Seoul, South Korea, 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/10.1145/2809695.2809712" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/sensys2015.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this paper we propose a novel algorithm for tracking people in highly dynamic industrial settings, such as construction sites. We observed both short term and long term changes in the environment; people were allowed to walk in different parts of the site on different days, the field of view of fixed cameras changed over time with the addition of walls, whereas radio and magnetic maps proved unstable with the movement of large structures. To make things worse, the uniforms and helmets that people wear for safety make them very hard to distinguish visually, necessitating the use of additional sensor modalities. In order to address these challenges, we designed a positioning system that uses both anonymous and id-linked sensor measurements and explores the use of cross-modality training to deal with environment dynamics. The system is evaluated in a real construction site and is shown to outperform state of the art multi-target tracking algorithms designed to operate in relatively stable environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/2809695.2809712</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Wen, Hongkai and Xiao, Zhuoling and Markham, Andrew and Trigoni, Niki}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Accurate Positioning via Cross-Modality Training}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450336314}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/2809695.2809712}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/2809695.2809712}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems (SenSys)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{239–251}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{wireless sensor networks, tracking}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Seoul, South Korea}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{SenSys '15}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/dcoss.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dcoss.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="7165020" class="col-sm-8"> <div class="title">Opportunistic Radio Assisted Navigation for Autonomous Ground Vehicles</div> <div class="author"> Hongkai Wen, Yiran Shen, <em>Savvas Papaioannou</em>, Winston Churchill, Niki Trigoni, and Paul Newman </div> <div class="periodical"> <em>In 2015 International Conference on Distributed Computing in Sensor Systems (DCOSS)</em>, 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/7165020" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Navigating autonomous ground vehicles with visual sensors has many advantages - it does not rely on global maps, yet is accurate and reliable even in GPS-denied environments. However, due to the limitation of the camera field of view, one typically has to record a large number of visual experiences for practical navigation. In this paper, we explore new avenues in linking together visual experiences, by opportunistically harvesting and sharing a variety of radio signals emitted by surrounding stationary access points and mobile devices. We propose a novel navigation approach, which exploits side-channel information of co-location to thread up visually-separated experiences with short exploration phases. The proposed approach empowers users to trade travel time for manual navigation effort, allowing them to choose the itinerary that best serves their needs. We evaluate the proposed approach with data collected from a typical urban area, and show that it achieves much better navigation performance in both reach ability and cost, comparing with the state of the arts that only use visual information.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">7165020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wen, Hongkai and Shen, Yiran and Papaioannou, Savvas and Churchill, Winston and Trigoni, Niki and Newman, Paul}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2015 International Conference on Distributed Computing in Sensor Systems (DCOSS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Opportunistic Radio Assisted Navigation for Autonomous Ground Vehicles}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{21-30}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/DCOSS.2015.22}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/mass2014.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mass2014.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="7035671" class="col-sm-8"> <div class="title">Fusion of Radio and Camera Sensor Data for Accurate Indoor Positioning</div> <div class="author"> <em>Savvas Papaioannou</em>, Hongkai Wen, Andrew Markham, and Niki Trigoni </div> <div class="periodical"> <em>In 2014 IEEE 11th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)</em>, 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.02952" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/7035671" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/mass2014.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Indoor positioning systems have received a lot of attention recently due to their importance for many location-based services, e.g. indoor navigation and smart buildings. Lightweight solutions based on WiFi and inertial sensing have gained popularity, but are not fit for demanding applications, such as expert museum guides and industrial settings, which typically require sub-meter location information. In this paper, we propose a novel positioning system, RAVEL (Radio And Vision Enhanced Localization), which fuses anonymous visual detections captured by widely available camera infrastructure, with radio readings (e.g. WiFi radio data). Although visual trackers can provide excellent positioning accuracy, they are plagued by issues such as occlusions and people entering/exiting the scene, preventing their use as a robust tracking solution. By incorporating radio measurements, visually ambiguous or missing data can be resolved through multi-hypothesis tracking. We evaluate our system in a complex museum environment with dim lighting and multiple people moving around in a space cluttered with exhibit stands. Our experiments show that although the WiFi measurements are not by themselves sufficiently accurate, when they are fused with camera data, they become a catalyst for pulling together ambiguous, fragmented, and anonymous visual tracklets into accurate and continuous paths, yielding typical errors below 1 meter.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">7035671</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Wen, Hongkai and Markham, Andrew and Trigoni, Niki}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2014 IEEE 11th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fusion of Radio and Camera Sensor Data for Accurate Indoor Positioning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{109-117}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/MASS.2014.52}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/EWSN14_Poster.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="EWSN14_Poster.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="EWSN2014" class="col-sm-8"> <div class="title">WiFi Sensors Meet Visual Tracking For An Accurate Positioning System</div> <div class="author"> <em>Savvas Papaioannou</em>, Hongkai Wen, Zhuoling Xiao, Andrew Markham, and Niki Trigoni </div> <div class="periodical"> <em>In 11th European Conference on Wireless Sensor Networks, (EWSN)</em>, Feb 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.cs.ox.ac.uk/ewsn14/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/ewsn14.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this poster abstract, we propose a new positioning technique that can localize people by combining WiFi information from their mobile devices with visual tracking. We show that the proposed approach can improve visual tracking by resolving motion and appearance ambiguities while at the same time can uniquely identify each person with their device ID</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">EWSN2014</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{WiFi Sensors Meet Visual Tracking For An Accurate Positioning System}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Papaioannou, Savvas and Wen, Hongkai and Xiao, Zhuoling and Markham, Andrew and Trigoni, Niki}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{11th European Conference on Wireless Sensor Networks, (EWSN)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2013</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/tecsPrev.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tecsPrev.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tecs" class="col-sm-8"> <div class="title">A Novel Low-Power Embedded Object Recognition System Working at Multi-Frames per Second</div> <div class="author"> Antonis Nikitakis, <em>Savvas Papaioannou</em>, and Ioannis Papaefstathiou </div> <div class="periodical"> <em>ACM Trans. Embed. Comput. Syst.</em>, Mar 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/abs/10.1145/2435227.2435229" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/tecs2013.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>One very important challenge in the field of multimedia is the implementation of fast and detailed Object Detection and Recognition systems. In particular, in the current state-of-the-art mobile multimedia systems, it is highly desirable to detect and locate certain objects within a video frame in real time. Although a significant number of Object Detection and Recognition schemes have been developed and implemented, triggering very accurate results, the vast majority of them cannot be applied in state-of-the-art mobile multimedia devices; this is mainly due to the fact that they are highly complex schemes that require a significant amount of processing power, while they are also time consuming and very power hungry. In this article, we present a novel FPGA-based embedded implementation of a very efficient object recognition algorithm called Receptive Field Cooccurrence Histograms Algorithm (RFCH). Our main focus was to increase its performance so as to be able to handle the object recognition task of today’s highly sophisticated embedded multimedia systems while keeping its energy consumption at very low levels. Our low-power embedded reconfigurable system is at least 15 times faster than the software implementation on a low-voltage high-end CPU, while consuming at least 60 times less energy. Our novel system is also 88 times more energy efficient than the recently introduced low-power multi-core Intel devices which are optimized for embedded systems. This is, to the best of our knowledge, the first system presented that can execute the complete complex object recognition task at a multi frame per second rate while consuming minimal amounts of energy, making it an ideal candidate for future embedded multimedia systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">tecs</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nikitakis, Antonis and Papaioannou, Savvas and Papaefstathiou, Ioannis}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Novel Low-Power Embedded Object Recognition System Working at Multi-Frames per Second}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{March 2013}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1s}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/2435227.2435229}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Trans. Embed. Comput. Syst.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2012</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/estimedia.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="estimedia.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="6507033" class="col-sm-8"> <div class="title">A novel low-power embedded object recognition system working at multi-frames per second (Best Paper Award)</div> <div class="author"> Antonis Nikitakis, <em>Savvas Papaioannou</em>, and Ioannis Papaefstathiou </div> <div class="periodical"> <em>In 2012 IEEE 10th Symposium on Embedded Systems for Real-time Multimedia</em>, Mar 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/6507033" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>One very important challenge in the field of multimedia is the implementation of fast and detailed Object Detection and Recognition systems. In particular, in the current state-of-the-art mobile multimedia systems, it is highly desirable to detect and locate certain objects within a video frame in real time. In this paper, we present a novel FPGA-based embedded implementation of a very efficient object recognition algorithm called Receptive Field Cooccurrence Histograms Algorithm(RFCH). Our main focus was to increase its performance so as to be able to handle the object recognition task of today’s highly sophisticated embedded multimedia systems while keeping its energy consumption at very low levels. Our low-power embedded reconfigurable system is at least 15 times faster than the software implementation on a low-voltage high-end CPU, while consuming at least 60 times less energy. Our novel system is also 88 times more energy efficient than the recently introduced low-power multi-core Intel devices which are optimized for embedded systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">6507033</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nikitakis, Antonis and Papaioannou, Savvas and Papaefstathiou, Ioannis}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2012 IEEE 10th Symposium on Embedded Systems for Real-time Multimedia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A novel low-power embedded object recognition system working at multi-frames per second (Best Paper Award)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{85-85}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ESTIMedia.2012.6507033}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">PETRA 2012</abbr> </div> <div id="petra" class="col-sm-8"> <div class="title">SIPE: A Sensor Information Processing Engine for Wellness Management Applications</div> <div class="author"> Andreas Savvides, <em>Savvas Papaioannou</em>, Sokratis Kartakis, Brendan Kohler, and George Demiris </div> <div class="periodical"> <em>In Proceedings of the 5th ACM International Conference on Pervasive Technologies Related to Assistive Environments (PETRA)</em>, Mar 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">petra</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Savvides, Andreas and Papaioannou, Savvas and Kartakis, Sokratis and Kohler, Brendan and Demiris, George}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 5th ACM International Conference on Pervasive Technologies Related to Assistive Environments (PETRA)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SIPE: A Sensor Information Processing Engine for Wellness Management Applications}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Savvas Papaioannou. Last updated: July 15, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-awards",title:"awards",description:"",section:"Navigation",handler:()=>{window.location.href="/awards"}},{id:"nav-media",title:"media",description:"",section:"Navigation",handler:()=>{window.location.href="/media"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"dropdown-service",title:"service",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-teaching",title:"teaching",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-contact",title:"contact",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"news-our-journal-paper-on-distributed-search-planning-in-3-d-environments-with-a-dynamically-varying-number-of-agents-has-been-published-in-the-ieee-transactions-on-systems-man-and-cybernetics-systems-tsmc-2023",title:"Our journal paper on \u201cDistributed Search Planning in 3-D Environments With a Dynamically...",description:"",section:"News"},{id:"news-our-paper-on-model-predictive-control-for-multiple-castaway-tracking-with-an-autonomous-aerial-agent-has-been-accepted-at-the-2023-european-control-conference-ecc-2023",title:"Our paper on \u201cModel Predictive Control For Multiple Castaway Tracking with an Autonomous...",description:"",section:"News"},{id:"news-our-paper-unscented-optimal-control-for-3d-coverage-planning-with-an-autonomous-uav-agent-has-been-accepted-at-the-2023-international-conference-on-unmanned-aircraft-systems-icuas-2023",title:"Our paper \u201cUnscented Optimal Control for 3D Coverage Planning with an Autonomous UAV...",description:"",section:"News"},{id:"news-our-papers-joint-estimation-and-control-for-multi-target-passive-monitoring-with-an-autonomous-uav-agent-and-distributed-control-for-3d-inspection-using-multi-uav-systems-have-been-accepted-at-the-31st-mediterranean-conference-on-control-and-automation-med-2023",title:"Our papers \u201cJoint Estimation and Control for Multi-Target Passive Monitoring with an Autonomous...",description:"",section:"News"},{id:"news-our-paper-cooperative-receding-horizon-3d-coverage-control-with-a-team-of-networked-aerial-agents-has-been-accepted-at-the-62nd-ieee-conference-on-decision-and-control-cdc-2023",title:"Our paper \u201cCooperative Receding Horizon 3D Coverage Control with a Team of Networked...",description:"",section:"News"},{id:"news-i-am-thrilled-to-announce-that-our-kios-coe-team-has-won-the-first-prize-in-the-competition-cooperative-aerial-robots-inspection-challenge-caric-that-took-place-during-the-flagship-62nd-ieee-conference-on-decision-and-control-cdc-2023-on-13-15-december-2023-in-singapore",title:"I am thrilled to announce that our KIOS CoE team has won the...",description:"",section:"News"},{id:"news-our-paper-entitled-hierarchical-fault-tolerant-coverage-control-for-an-autonomous-aerial-agent-has-been-accepted-at-the-12th-ifac-symposium-on-fault-detection-supervision-and-safety-of-technical-processes-safeprocess-2024",title:"Our paper entitled \u201cHierarchical Fault-Tolerant Coverage Control for an Autonomous Aerial Agent\u201c has...",description:"",section:"News"},{id:"news-our-paper-synergising-human-like-responses-and-machine-intelligence-for-planning-in-disaster-response-has-been-accepted-at-the-2024-ieee-world-congress-on-computational-intelligence-wcci-2024-international-joint-conference-on-neural-networks-ijcnn",title:"Our paper \u201cSynergising Human-Like Responses and Machine Intelligence for Planning in Disaster Response\u201c...",description:"",section:"News"},{id:"news-our-paper-automated-real-time-inspection-in-indoor-and-outdoor-3d-environments-with-cooperative-aerial-robots-has-been-accepted-at-the-2024-international-conference-on-unmanned-aircraft-systems-icuas-2024",title:"Our paper \u201cAutomated Real-Time Inspection in Indoor and Outdoor 3D Environments with Cooperative...",description:"",section:"News"},{id:"news-we-have-won-the-second-prize-in-the-multi-robot-perception-and-navigation-challenges-in-logistics-and-inspection-tasks-competition-held-as-part-of-the-2024-ieee-rsj-international-conference-on-intelligent-robots-and-systems-iros-2024-in-abu-dhabi-october-14-18-2024",title:"We have won the Second Prize in the \u201cMulti-Robot Perception and Navigation Challenges...",description:"",section:"News"},{id:"news-our-manuscript-entitled-rolling-horizon-coverage-control-with-collaborative-autonomous-agents-has-been-accepted-for-publication-in-the-upcoming-theme-issue-the-road-forward-with-swarm-systems-of-philosophical-transactions-of-the-royal-society-a-mathematical-physical-and-engineering-sciences-volume-383-issue-2289-2025",title:"Our manuscript, entitled \u201cRolling Horizon Coverage Control with Collaborative Autonomous Agents,\u201c has been...",description:"",section:"News"},{id:"news-our-journal-paper-jointly-optimized-trajectory-generation-and-camera-control-for-3d-coverage-planning-has-been-accepted-for-publication-in-an-upcoming-issue-of-the-ieee-transactions-on-mobile-computing-tmc-2025",title:"Our journal paper \u201cJointly-optimized Trajectory Generation and Camera Control for 3D Coverage Planning\u201c...",description:"",section:"News"},{id:"news-three-papers-have-been-accepted-for-presentation-and-publication-in-the-proceedings-of-the-23rd-european-control-conference-ecc-2025-june-24-27-2025-1-data-driven-predictive-planning-and-control-for-aerial-3d-inspection-with-back-face-elimination-2-multiple-target-tracking-using-a-uav-swarm-in-maritime-environments-and-3-adaptive-out-of-control-point-pattern-detection-in-sequential-random-finite-set-observations",title:"Three papers have been accepted for presentation and publication in the proceedings of...",description:"",section:"News"},{id:"news-our-paper-entitled-vlm-rrt-vision-language-model-guided-rrt-search-for-autonomous-uav-navigation-has-been-accepted-for-presentation-in-the-2025-international-conference-on-unmanned-aircraft-systems-icuas-2025-to-be-held-in-charlotte-north-carolina-usa-2025",title:"Our paper entitled \u201cVLM-RRT: Vision Language Model Guided RRT Search for Autonomous UAV...",description:"",section:"News"},{id:"news-new-paper-accepted-to-ieee-robotics-and-automation-magazine-ram-2025-cooperative-aerial-robot-inspection-challenge-a-benchmark-for-heterogeneous-multi-uav-planning-and-lessons-learned",title:"New paper accepted to IEEE Robotics and Automation Magazine (RAM), 2025 - \u201cCooperative...",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%70%61%70%61%69%6F%61%6E%6E%6F%75.%73%61%76%76%61%73@%75%63%79.%61%63.%63%79","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0003-3149-4202","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=liBM_1kAAAAJ&hl=en","_blank")}},{id:"socials-semantic-scholar",title:"Semantic Scholar",section:"Socials",handler:()=>{window.open("https://www.semanticscholar.org/author/Savvas-Papaioannou/31451730","_blank")}},{id:"socials-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Savvas-Papaioannou/","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/savvas-papaioannou1","_blank")}},{id:"socials-work",title:"Work",section:"Socials",handler:()=>{window.open("https://www.kios.ucy.ac.cy/","_blank")}},{id:"socials-dblp",title:"DBLP",section:"Socials",handler:()=>{window.open("https://dblp.org/pid/129/5573","_blank")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>